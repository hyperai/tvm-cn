---
title: 部署深度学习模型
---

# 部署深度学习模型

TVM 可将模型部署到各种不同的平台。以下操作指南描述了如何准备模型，并将其部署到多种支持的后端。

* [在 Adreno™ 上部署预训练模型](https://tvm.apache.org/docs/v0.13.0/how_to/deploy_models/deploy_model_on_adreno.html#sphx-glr-how-to-deploy-models-deploy-model-on-adreno-py)
* [使用 tvmc 接口在 Adreno™ 上部署预训练模型](https://tvm.apache.org/docs/v0.13.0/how_to/deploy_models/deploy_model_on_adreno_tvmc.html#sphx-glr-how-to-deploy-models-deploy-model-on-adreno-tvmc-py)
* [在 Android 上部署预训练模型](deploy_android)
* [在 Jetson Nano 上部署预训练模型](deploy_nano)
* [在树莓派上部署预训练模型](deploy_pi)
* [编译 PyTorch 对象检测模型](compile_od)
* [使用 TVM 部署框架预量化模型](deploy_prequan)
* [使用 TVM 部署框架预量化模型 - 第 3 部分（TFLite）](deploy_prequan_3)
* [在 CUDA 上部署量化模型](deploy_quan)
* [在 CPU 上部署 Hugging Face 剪枝模型](hugging_face)
