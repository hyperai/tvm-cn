---
title: 部署深度学习模型
---

# 部署深度学习模型

TVM 可将模型部署到各种不同的平台。以下操作指南描述了如何准备模型，并将其部署到多种支持的后端。

* [在 Android 上部署预训练模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_model_on_android.html#sphx-glr-how-to-deploy-models-deploy-model-on-android-py)
* [在树莓派上部署预训练模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_model_on_rasp.html#sphx-glr-how-to-deploy-models-deploy-model-on-rasp-py)
* [编译 PyTorch 对象检测模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_object_detection_pytorch.html#sphx-glr-how-to-deploy-models-deploy-object-detection-pytorch-py)
* [使用 TVM 部署框架预量化模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_prequantized.html#sphx-glr-how-to-deploy-models-deploy-prequantized-py)
* [使用 TVM 部署框架预量化模型 - 第 3 部分 (TFLite)](https://tvm.apache.org/docs/how_to/deploy_models/deploy_prequantized_tflite.html#sphx-glr-how-to-deploy-models-deploy-prequantized-tflite-py)
* [在 CUDA 上部署量化模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_quantized.html#sphx-glr-how-to-deploy-models-deploy-quantized-py)
* [在 CPU 上部署 Hugging Face 剪枝模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_sparse.html#sphx-glr-how-to-deploy-models-deploy-sparse-py)
* [部署 Single Shot Multibox Detector (SSD) 模型](https://tvm.apache.org/docs/how_to/deploy_models/deploy_ssd_gluoncv.html#sphx-glr-how-to-deploy-models-deploy-ssd-gluoncv-py)
